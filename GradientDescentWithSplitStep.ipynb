{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GradientDescentWithSplitStep.ipynb\"",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNL5Hd4ZD7HOak00mf2uj75",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kuznechek/Numerical-methods/blob/main/GradientDescentWithSplitStep.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LhCY1GIMEnck"
      },
      "source": [
        "# Градиентный спуск с дроблением шага"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GaoX7w5cE1C0"
      },
      "source": [
        "Исходные параметры:\n",
        "\n",
        "Одномерный тензор Х = [0.686, 2.157, -0.137]\n",
        "Шаг = 0.01, коэффициент дробления = 0.5\n",
        "\n",
        "Заданная точность = 0.0001"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XtgNczbTa8QJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88bc202e-7366-43df-ce19-e53010eecc16"
      },
      "source": [
        "import torch\n",
        "\n",
        "def function(w):\n",
        "  w1 = w[0] \n",
        "  w2 = w[1]\n",
        "  w3 = w[2]\n",
        "  result = 3 *w1**2 + w2**2 + 5*w3**2 - w1*w2 + 2*w1*w3 + 6*w1 - 5*w2\n",
        "  return result\n",
        "\n",
        "x = torch.tensor([0.686, 2.157, -0.137], requires_grad = True)\n",
        "alpha = 0.01\n",
        "k = 0\n",
        "norma = 10\n",
        "print('Начальные координаты : X =', x.data)\n",
        "print('')\n",
        "\n",
        "while (norma >= 0.0001):\n",
        "  k += 1\n",
        "  fx = function(x)\n",
        "  fx.backward()\n",
        "  gx = x.grad\n",
        "  x_new = x - alpha*gx\n",
        "  fx_new = function(x_new)  \n",
        "  fx_new.backward()\n",
        "  norma = torch.norm(fx - fx_new)\n",
        "  if norma >= abs(alpha * torch.norm(gx)):\n",
        "    alpha *= 0.5\n",
        "  else:\n",
        "    x = x_new \n",
        "  print('Итерация :', k)\n",
        "  print('X* =', x_new.data)\n",
        "  print('f(X*) :', fx_new)\n",
        "  print('Норма :', norma)\n",
        "  print(' ')\n",
        " \n",
        "  x.grad.zero_()\n",
        "print('Всего итераций :', k)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Начальные координаты : X = tensor([ 0.6860,  2.1570, -0.1370])\n",
            "\n",
            "Итерация : 1\n",
            "X* = tensor([ 0.6091,  2.1707, -0.1370])\n",
            "f(X*) : tensor(-2.7688, grad_fn=<SubBackward0>)\n",
            "Норма : tensor(0.5905, grad_fn=<CopyBackwards>)\n",
            " \n",
            "Итерация : 2\n",
            "X* = tensor([ 0.6476,  2.1639, -0.1370])\n",
            "f(X*) : tensor(-2.4784, grad_fn=<SubBackward0>)\n",
            "Норма : tensor(0.3000, grad_fn=<CopyBackwards>)\n",
            " \n",
            "Итерация : 3\n",
            "X* = tensor([ 0.6668,  2.1604, -0.1370])\n",
            "f(X*) : tensor(-2.3296, grad_fn=<SubBackward0>)\n",
            "Норма : tensor(0.1512, grad_fn=<CopyBackwards>)\n",
            " \n",
            "Итерация : 4\n",
            "X* = tensor([ 0.6764,  2.1587, -0.1370])\n",
            "f(X*) : tensor(-2.2543, grad_fn=<SubBackward0>)\n",
            "Норма : tensor(0.0759, grad_fn=<CopyBackwards>)\n",
            " \n",
            "Итерация : 5\n",
            "X* = tensor([ 0.6812,  2.1579, -0.1370])\n",
            "f(X*) : tensor(-2.2164, grad_fn=<SubBackward0>)\n",
            "Норма : tensor(0.0380, grad_fn=<CopyBackwards>)\n",
            " \n",
            "Итерация : 6\n",
            "X* = tensor([ 0.6836,  2.1574, -0.1370])\n",
            "f(X*) : tensor(-2.1974, grad_fn=<SubBackward0>)\n",
            "Норма : tensor(0.0190, grad_fn=<CopyBackwards>)\n",
            " \n",
            "Итерация : 7\n",
            "X* = tensor([ 0.6848,  2.1572, -0.1370])\n",
            "f(X*) : tensor(-2.1879, grad_fn=<SubBackward0>)\n",
            "Норма : tensor(0.0095, grad_fn=<CopyBackwards>)\n",
            " \n",
            "Итерация : 8\n",
            "X* = tensor([ 0.6854,  2.1571, -0.1370])\n",
            "f(X*) : tensor(-2.1831, grad_fn=<SubBackward0>)\n",
            "Норма : tensor(0.0048, grad_fn=<CopyBackwards>)\n",
            " \n",
            "Итерация : 9\n",
            "X* = tensor([ 0.6857,  2.1571, -0.1370])\n",
            "f(X*) : tensor(-2.1808, grad_fn=<SubBackward0>)\n",
            "Норма : tensor(0.0024, grad_fn=<CopyBackwards>)\n",
            " \n",
            "Итерация : 10\n",
            "X* = tensor([ 0.6858,  2.1570, -0.1370])\n",
            "f(X*) : tensor(-2.1796, grad_fn=<SubBackward0>)\n",
            "Норма : tensor(0.0012, grad_fn=<CopyBackwards>)\n",
            " \n",
            "Итерация : 11\n",
            "X* = tensor([ 0.6859,  2.1570, -0.1370])\n",
            "f(X*) : tensor(-2.1790, grad_fn=<SubBackward0>)\n",
            "Норма : tensor(0.0006, grad_fn=<CopyBackwards>)\n",
            " \n",
            "Итерация : 12\n",
            "X* = tensor([ 0.6860,  2.1570, -0.1370])\n",
            "f(X*) : tensor(-2.1787, grad_fn=<SubBackward0>)\n",
            "Норма : tensor(0.0003, grad_fn=<CopyBackwards>)\n",
            " \n",
            "Итерация : 13\n",
            "X* = tensor([ 0.6860,  2.1570, -0.1370])\n",
            "f(X*) : tensor(-2.1785, grad_fn=<SubBackward0>)\n",
            "Норма : tensor(0.0002, grad_fn=<CopyBackwards>)\n",
            " \n",
            "Итерация : 14\n",
            "X* = tensor([ 0.6860,  2.1570, -0.1370])\n",
            "f(X*) : tensor(-2.1785, grad_fn=<SubBackward0>)\n",
            "Норма : tensor(7.5340e-05, grad_fn=<CopyBackwards>)\n",
            " \n",
            "Всего итераций : 14\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}